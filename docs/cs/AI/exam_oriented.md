## Chap 3


1. 人工智能开发中的特征工程是指自动选择最适合的特征进行模型训练的过程。 

??? tip "答案"
    - 错误

    - 特征工程是指从原始数据中提取、转换、选择和创建特征，以提高机器学习模型性能的过程。

---




2. 在训练深度学习模型时，增加模型的复杂性总是能提高其在测试数据上的表现。 

??? tip "答案"
    - 错误

    - **过拟合** (Overfitting)：当模型的复杂性增加时，它可能会在训练数据上表现得非常好，但**在测试数据上表现不佳**。这种现象称为过拟合。过拟合的模型在训练数据上**学到了太多的细节和噪声**，导致它**无法很好地泛化到新的、未见过的数据**。

## Chap 4


## Chap 5

|名词|描述|
|---|----|
|支持向量机（SVM）|监督学习：寻找**最佳的划分两类点的一条直线**（超平面），同时最大化类别之间的间隔|
|交叉验证|评估并优化模型：通过将数据集划分为多个子集，反复训练和验证模型，以获得更稳定和可靠的性能评估结果。有助于**避免模型过拟合和欠拟合**|
|梯度下降|优化模型：为了**最小化损失函数**，通过沿损失函数的梯度方向不停迭代变化，从而靠近“谷底”|
|决策树|监督学习：选择最佳特征来构建一棵决策树，使得决策自动且合理，用于分类和回归|
|K-means|无监督学习：让**无标注**的数据自行分类出各个cluster，让点有归属，每次分类点就让它去最近的cluster，并且及时更新cluster centroid|
|KNN|监督学习：帮助样本点分类，不过只关注样本点**周围已知样本点**的情况|
|逻辑回归|监督学习：实际上是一种分类算法（二分类），利用逻辑函数（sigmoid）将线性回归的输出映射到(0,1)区间|




1. 在k折交叉验证中，数据集被分成k个不同的子集，每次使用一个子集作为验证集，其余子集作为训练集。 (判断题) 

??? tip "答案"
    - 正确

    - 在 k 折交叉验证中，数据集被分成 k 个不同的子集（或称为折）。每次使用一个子集作为验证集，其余 k-1 个子集作为训练集。这个过程重复 k 次，每次选择不同的子集作为验证集。最终，模型的性能通过所有 k 次验证的结果进行评估。

2. 在防止过拟合的技术中，下列哪种方法通过在模型中引入惩罚项来减少过拟合？ 单选题 (5 分)

A . 交叉验证

B . 正则化

C . 数据扩充

D . 提升法 为什么

??? tip "答案"
    - B. 正则化

    - **正则化** 是一种通过在损失函数中添加惩罚项来减少模型复杂性的方法，从而防止过拟合。常见的正则化方法包括 L1 正则化（Lasso）和 L2 正则化（Ridge）。这些方法通过在损失函数中添加参数的绝对值或平方和的惩罚项，迫使模型参数变小，从而减少模型的复杂性和过拟合的风险。

    - 交叉验证是一种评估模型性能的方法，通过将数据集划分为多个子集，反复训练和验证模型，以获得更稳定的性能评估结果。虽然交叉验证有助于选择模型和参数，但它本身并不通过引入惩罚项来减少过拟合。

    - 数据扩充是一种通过生成更多训练数据来防止过拟合的方法，特别是在图像处理领域。它通过对现有数据进行变换（如旋转、缩放、翻转等）来生成新的数据样本，从而增加数据集的多样性。但它并不涉及在模型中引入惩罚项。

    - 提升法（Boosting）是一种集成学习方法，通过组合多个弱分类器来提高模型的性能。虽然提升法可以减少过拟合，但它的主要机制是通过加权组合多个模型，而不是通过在模型中引入惩罚项。


3. 